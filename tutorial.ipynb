{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tutorial\n",
    "\n",
    "This tutorial takes you through the Flair library. \n",
    "\n",
    "## NLP base types\n",
    "\n",
    "The Sentence object is the central object to our library. It holds a Sentence, consisting of Tokens. To this object, various layers of linguistic annotation may be added. This is also the central object for embedding your text.\n",
    "\n",
    "Let's illustrate this with an example sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"The grass is green .\" - 5 Tokens\n"
     ]
    }
   ],
   "source": [
    "# The sentence objects holds a sentence that we may want to embed\n",
    "from flair.data import Sentence\n",
    "\n",
    "# Make a sentence object by passing a whitespace tokenized string\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# Print the object to see what's in there\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each word in a sentence is a Token object. You can directly access a token using the token_id. Each token has attributes, such as an id and a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 4 green\n"
     ]
    }
   ],
   "source": [
    "print(sentence[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also iterate over all tokens in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The\nToken: 2 grass\nToken: 3 is\nToken: 4 green\nToken: 5 .\n"
     ]
    }
   ],
   "source": [
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens can also have tags, such as a named entity tag. In this example, we're adding an NER tag of type 'color' to \n",
    "the word 'green' in the example sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grass is green <color> .\n"
     ]
    }
   ],
   "source": [
    "# add a tag to a word in the sentence\n",
    "sentence[4].add_tag('ner', 'color')\n",
    "\n",
    "# print the sentence with all tags of this type\n",
    "print(sentence.to_ner_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging with Pre-Trained Models\n",
    "\n",
    "Now, lets use a pre-trained model for named entity recognition (NER). \n",
    "This model was trained over the English CoNLL-03 task and can recognize 4 different entity\n",
    "types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aakbik/.environments/flair/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'flair.tagging_model.SequenceTaggerLSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "from flair.tagging_model import SequenceTaggerLSTM\n",
    "\n",
    "tagger = SequenceTaggerLSTM.load('ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All you need to do is use the `predict()` method of the tagger on a sentence. This will add predicted tags to the tokens\n",
    "in the sentence. Lets use a sentence with two named\n",
    "entities: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George <B-PER> Washington <E-PER> went to Washington <S-LOC> .\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('George Washington went to Washington .')\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "print(sentence.to_tag_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You chose which pre-trained model you load by passing the appropriate \n",
    "string you pass to the `load()` method of the `SequenceTaggerLSTM` class. Currently, the following pre-trained models\n",
    "are provided (more coming): \n",
    " \n",
    "\n",
    " 'ner' : Conll-03 Named Entity Recognition (English)     \n",
    "\n",
    " 'chunk' : Conll-2000 Syntactic Chunking (English)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "We provide a set of classes with which you can embed the words in sentences in various ways. Note that all embedding \n",
    "classes inherit from the `TextEmbeddings` class and implement the `embed()` method which you need to call \n",
    "to embed your text. This means that for most users of Flair, the complexity of different embeddings remains hidden \n",
    "behind this interface. Simply instantiate the embedding class you require and call `embed()` to embed your text.\n",
    "\n",
    "All embeddings produced with our methods are pytorch vectors, so they can be immediately used for training and \n",
    "fine-tuning.\n",
    "\n",
    "### Classic Word Embeddings\n",
    "\n",
    "Classic word embeddings are static and word-level, meaning that each distinc word gets exactly one pre-computed \n",
    "embedding. Most embeddings fall under this class, including the popular GloVe or Komnios embeddings. \n",
    "\n",
    "Simply instantiate the WordEmbeddings class and pass a string identifier of the embedding you wish to load. So, if \n",
    "you want to use GloVe embeddings, pass the string 'glove' to the constructor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all embeddings inherit from the TextEmbeddings class. Init a simple glove embedding.\n",
    "from flair.embeddings import WordEmbeddings\n",
    "glove_embedding = WordEmbeddings('glove')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create an example sentence and call the embedding's `embed()` method. You always pass a list of sentences to \n",
    "this method since some embedding types make use of batching to increase speed. So if you only have one sentence, \n",
    "pass a list containing only one sentence:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The\ntorch.Size([100])\nToken: 2 grass\ntorch.Size([100])\nToken: 3 is\ntorch.Size([100])\nToken: 4 green\ntorch.Size([100])\nToken: 5 .\ntorch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# embed a sentence using glove.\n",
    "from flair.data import Sentence\n",
    "sentence = Sentence('The grass is green .')\n",
    "glove_embedding.embed(sentences=[sentence])\n",
    "\n",
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints out the tokens and their embeddings. GloVe embeddings are pytorch vectors of dimensionality 100.\n",
    "\n",
    "You choose which pre-trained embeddings you load by passing the appropriate \n",
    "string you pass to the constructor of the `WordEmbeddings` class. Currently, the following static embeddings\n",
    "are provided (more coming): \n",
    " \n",
    "'glove' : GloVe embeddings \n",
    "\n",
    "'extvec' : Komnios embeddings \n",
    "\n",
    "'ft-crawl' : FastText embeddings \n",
    "\n",
    "'ft-german' : German FastText embeddings \n",
    "\n",
    "So, if you want to load German FastText embeddings, instantiate the method as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_embedding = WordEmbeddings('ft-german')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual String Embeddings\n",
    "\n",
    "\n",
    "Contextual string embeddings are [powerful embeddings](https://drive.google.com/file/d/17yVpFA7MmXaQFTe-HDpZuqw9fJlmzg56/view?usp=sharing)\n",
    " that capture latent syntactic-semantic information that goes beyond\n",
    "standard word embeddings. Key differences are: (1) they are trained without any explicit notion of words and\n",
    "thus fundamentally model words as sequences of characters. And (2) they are **contextualized** by their\n",
    "surrounding text, meaning that the *same word will have different embeddings depending on its\n",
    "contextual use*.\n",
    "\n",
    "With Flair, you can use these embeddings simply by instantiating the appropriate embedding class, same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORWARD language mode loaded\non cuda:\nFalse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<flair.data.Sentence at 0x7fabc51055f8>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the CharLMEmbedding also inherits from the TextEmbeddings class\n",
    "from flair.embeddings import CharLMEmbeddings\n",
    "charlm_embedding_forward = CharLMEmbeddings('news-forward')\n",
    "\n",
    "# embed a sentence using CharLM.\n",
    "from flair.data import Sentence\n",
    "sentence = Sentence('The grass is green .')\n",
    "charlm_embedding_forward.embed(sentences=[sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You choose which embeddings you load by passing the appropriate \n",
    "string you pass to the constructor of the `CharLMEmbeddings` class. Currently, the following contextual string\n",
    " embeddings\n",
    "are provided (more coming): \n",
    " \n",
    "| ID | Language | Embedding | \n",
    "| -------------     | ------------- | ------------- |\n",
    "| 'news-forward'    | English | Forward LM embeddings over 1 billion word corpus |\n",
    "| 'news-backward'   | English | Backward LM embeddings over 1 billion word corpus |\n",
    "| 'mix-forward'     | English | Forward LM embeddings over mixed corpus (Web, Wikipedia, Subtitles) |\n",
    "| 'mix-backward'    | English | Backward LM embeddings over mixed corpus (Web, Wikipedia, Subtitles) |\n",
    "| 'german-forward'  | German  | Forward LM embeddings over mixed corpus (Web, Wikipedia, Subtitles) |\n",
    "| 'german-backward' | German  | Backward LM embeddings over mixed corpus (Web, Wikipedia, Subtitles) |\n",
    "\n",
    "So, if you want to load embeddings from the English news backward LM model, instantiate the method as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BACKWARD language mode loaded\non cuda:\nFalse\n"
     ]
    }
   ],
   "source": [
    "charlm_embedding_backward = CharLMEmbeddings('news-backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}